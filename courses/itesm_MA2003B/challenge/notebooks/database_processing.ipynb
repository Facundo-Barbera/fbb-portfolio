{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1061ecac43f56250",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:32:27.570658Z",
     "start_time": "2025-08-21T18:32:27.175648Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f86fe0fddffb71c",
   "metadata": {},
   "source": [
    "# Database Processing Notebook\n",
    "\n",
    "This notebook is a critical step in the initial exploration of the datasets provided for the air quality project by SIMA.\n",
    "When we first received the datasets, they were in Excel format and contained multiple sheets, and different formats.\n",
    "The goal of this notebook is to process these datasets individually, to extract the relevant information and combine them into a single, unified dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9dfa20f97225e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:32:27.577435Z",
     "start_time": "2025-08-21T18:32:27.574539Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = {\n",
    "\t'stations': {\n",
    "\t\t'SE': 'sureste',\n",
    "\t\t'NE': 'noreste',\n",
    "\t\t'CE': 'centro',\n",
    "\t\t'NO': 'noroeste',\n",
    "\t\t'SO': 'suroeste',\n",
    "\t\t'NO2': ['noroeste2', 'noroeste 2'],\n",
    "\t\t'NTE': 'norte',\n",
    "\t\t'NE2': ['noreste2', 'noreste 2'],\n",
    "\t\t'SE2': ['sureste2', 'sureste 2'],\n",
    "\t\t'SO2': ['suroeste2', 'suroeste 2'],\n",
    "\t\t'SUR': 'sur',\n",
    "\t\t'NTE2': ['norte2', 'norte 2'],\n",
    "\t\t'SE3': ['sureste3', 'sureste 3'],\n",
    "\t\t'NE3': ['noreste3', 'noreste 3'],\n",
    "\t\t'NO3': ['noroeste3', 'noroeste 3']\n",
    "\t},\n",
    "\t'contaminants': {\n",
    "\t\t'PM10': 'Partículas menores a 10 micras',\n",
    "\t\t'PM2.5': 'Partículas menores a 2.5 micras',\n",
    "\t\t'O3': 'Ozono',\n",
    "\t\t'SO2': 'Dióxido de azufre',\n",
    "\t\t'NO2': 'Dióxido de nitrógeno',\n",
    "\t\t'CO': 'Monóxido de carbono',\n",
    "\t\t'NO': 'Monóxido de nitrógeno',\n",
    "\t\t'NOX': 'Óxidos de nitrógeno'\n",
    "\t}\n",
    "}\n",
    "\n",
    "additional_labels = {\n",
    "\t'parameters': {\n",
    "\t\t'TOUT': 'Temperatura',\n",
    "\t\t'RH': 'Humedad Relativa',\n",
    "\t\t'SR': 'Radiación Solar',\n",
    "\t\t'RAINF': 'Precipitación',\n",
    "\t\t'PRS': 'Presión Atmosférica',\n",
    "\t\t'WSR': 'Velocidad del Viento',\n",
    "\t\t'WDR': 'Dirección del Viento'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c171e0f2df3fc36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:32:46.292092Z",
     "start_time": "2025-08-21T18:32:27.580545Z"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Dataset one\n",
    "df_2020_2021_all_stations = pd.read_excel(\n",
    "\tPath(\"../data/raw/DATOS HISTÓRICOS 2020_2021_TODAS ESTACIONES.xlsx\"),\n",
    "\tsheet_name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46d0b1461c2061ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:32:46.412061Z",
     "start_time": "2025-08-21T18:32:46.353545Z"
    }
   },
   "outputs": [],
   "source": [
    "# Process dataset 1\n",
    "frames = []\n",
    "for name, frame in df_2020_2021_all_stations.items():\n",
    "\tif name == 'NOROESTE3':\n",
    "\t\tcontinue\n",
    "\tfor code, codename in labels['stations'].items():\n",
    "\t\tframe_copy = frame.copy()\n",
    "\t\tif isinstance(codename, list):\n",
    "\t\t\tif any(name.upper() == cn.upper() for cn in codename):\n",
    "\t\t\t\tframe_copy['station_code'] = code\n",
    "\t\t\t\tframes.append(frame_copy)\n",
    "\t\telse:\n",
    "\t\t\tif name.upper() == codename.upper():\n",
    "\t\t\t\tframe_copy['station_code'] = code\n",
    "\t\t\t\tframes.append(frame_copy)\n",
    "\n",
    "\n",
    "df_2020_2021_all_stations_processed = pd.concat(frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc0c7a5753c95168",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:33:02.095164Z",
     "start_time": "2025-08-21T18:32:46.416792Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset two\n",
    "df_2022_2023_all_stations = pd.read_excel(\n",
    "\tPath(\"../data/raw/DATOS HISTÓRICOS 2022_2023_TODAS ESTACIONES.xlsx\"),\n",
    "\tsheet_name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a71f7c0532ed567",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:33:02.165635Z",
     "start_time": "2025-08-21T18:33:02.130423Z"
    }
   },
   "outputs": [],
   "source": [
    "# Process dataset 2\n",
    "frames = []\n",
    "for name, frame in df_2022_2023_all_stations.items():\n",
    "\tfor code, codename in labels['stations'].items():\n",
    "\t\tframe_copy = frame.copy()\n",
    "\t\tif isinstance(codename, list):\n",
    "\t\t\tif any(name.upper() == cn.upper() for cn in codename):\n",
    "\t\t\t\tframe_copy['station_code'] = code\n",
    "\t\t\t\tframes.append(frame_copy)\n",
    "\t\telse:\n",
    "\t\t\tif name.upper() == codename.upper():\n",
    "\t\t\t\tframe_copy['station_code'] = code\n",
    "\t\t\t\tframes.append(frame_copy)\n",
    "\n",
    "\n",
    "df_2022_2023_all_stations_processed = pd.concat(frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97a3084a703f680f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:33:15.937968Z",
     "start_time": "2025-08-21T18:33:02.171528Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset three\n",
    "df_2023_2024_all_stations = pd.read_excel(\n",
    "\tPath(\"../data/raw/DATOS HISTÓRICOS 2023_2024_TODAS ESTACIONES_ITESM.xlsx\"),\n",
    "\tsheet_name='Param_horarios_Estaciones',\n",
    "\theader=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "597fc61e78684854",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:33:16.395354Z",
     "start_time": "2025-08-21T18:33:15.973770Z"
    }
   },
   "outputs": [],
   "source": [
    "# Process dataset 3\n",
    "stations_map = labels['stations']\n",
    "\n",
    "station_name_to_code = {}\n",
    "for code, names in stations_map.items():\n",
    "    if isinstance(names, list):\n",
    "        for name in names:\n",
    "            station_name_to_code[name.upper()] = code\n",
    "    else:\n",
    "        station_name_to_code[names.upper()] = code\n",
    "\n",
    "stations_row = df_2023_2024_all_stations.iloc[0, 1:].astype(str).str.strip()\n",
    "vars_row = df_2023_2024_all_stations.iloc[1, 1:].astype(str).str.strip()\n",
    "\n",
    "full_body = df_2023_2024_all_stations.iloc[3:].reset_index(drop=True)\n",
    "dates = pd.to_datetime(full_body.iloc[:, 0], errors=\"coerce\", dayfirst=True)\n",
    "body = full_body.iloc[:, 1:]\n",
    "\n",
    "\n",
    "contaminants = list(labels[\"contaminants\"].keys())\n",
    "\n",
    "frames = []\n",
    "for station in stations_row.unique():\n",
    "    if pd.isna(station) or station == \"nan\" or station.upper() not in station_name_to_code:\n",
    "        continue\n",
    "\n",
    "    # Find which columns contain data for the current station\n",
    "    station_columns = stations_row[stations_row == station].index.tolist()\n",
    "\n",
    "    station_data = {\n",
    "        \"station_code\": station_name_to_code[station.upper()],\n",
    "        \"date\": dates\n",
    "    }\n",
    "\n",
    "    for col_idx in station_columns:\n",
    "        if col_idx not in vars_row.index or col_idx not in body.columns:\n",
    "            print(f\"Warning: Column label {col_idx} not found in vars_row or body.\")\n",
    "            continue\n",
    "\n",
    "        var_name = vars_row.loc[col_idx]\n",
    "        # Normalize known aliases in dataset 3 (only)\n",
    "        if var_name == \"WDV\":\n",
    "            var_name = \"WDR\"\n",
    "\n",
    "        if var_name in contaminants or var_name in additional_labels[\"parameters\"]:\n",
    "            column_data = body.loc[:, col_idx]\n",
    "            station_data[var_name] = pd.to_numeric(column_data, errors='coerce')\n",
    "\n",
    "    if len(station_data) > 3:\n",
    "        station_df = pd.DataFrame(station_data)\n",
    "        frames.append(station_df)\n",
    "\n",
    "\n",
    "df_2023_2024_all_stations_processed = pd.concat(frames, ignore_index=True)\n",
    "\n",
    "if 'date' in df_2023_2024_all_stations_processed.columns:\n",
    "    mask_not_2024 = df_2023_2024_all_stations_processed['date'].isna() | (df_2023_2024_all_stations_processed['date'].dt.year != 2024)\n",
    "    df_2023_2024_all_stations_processed_no_2024 = df_2023_2024_all_stations_processed.loc[mask_not_2024].reset_index(drop=True)\n",
    "else:\n",
    "    df_2023_2024_all_stations_processed_no_2024 = df_2023_2024_all_stations_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10ac78a1c82a2a0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:33:26.459357Z",
     "start_time": "2025-08-21T18:33:16.402888Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset four\n",
    "df_2024_all_stations = pd.read_excel(\n",
    "    Path(\"../data/raw/BD 2024.xlsx\"),\n",
    "    sheet_name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b578c7fbedac456e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:33:26.602481Z",
     "start_time": "2025-08-21T18:33:26.507469Z"
    }
   },
   "outputs": [],
   "source": [
    "# Process dataset 4\n",
    "frames_2024 = []\n",
    "\n",
    "param_codes_2024 = list(labels[\"contaminants\"].keys()) + list(additional_labels[\"parameters\"].keys())\n",
    "\n",
    "for sheet_name, frame in df_2024_all_stations.items():\n",
    "    code_clean = str(sheet_name).strip().upper()\n",
    "    if code_clean in labels['stations'].keys():\n",
    "        f = frame.copy()\n",
    "        rename_map = {}\n",
    "\n",
    "        for c in f.columns:\n",
    "            c_str = str(c).strip()\n",
    "            c_upper = c_str.upper()\n",
    "            c_lower = c_str.lower()\n",
    "\n",
    "            if c_lower.startswith('fecha'):\n",
    "                rename_map[c] = 'date'\n",
    "                continue\n",
    "\n",
    "            match = next((code for code in param_codes_2024 if c_upper.startswith(code)), None)\n",
    "\n",
    "            if match:\n",
    "                rename_map[c] = match\n",
    "\n",
    "        if rename_map:\n",
    "            f = f.rename(columns=rename_map)\n",
    "\n",
    "        f = f.loc[:, ~f.columns.duplicated()].copy()\n",
    "\n",
    "        if 'date' in f.columns:\n",
    "            f['date'] = pd.to_datetime(f['date'], errors='coerce', dayfirst=True)\n",
    "\n",
    "        keep_cols = []\n",
    "\n",
    "        if 'date' in f.columns:\n",
    "            keep_cols.append('date')\n",
    "\n",
    "        keep_cols += [code for code in param_codes_2024 if code in f.columns]\n",
    "\n",
    "        if keep_cols:\n",
    "            f = f.loc[:, keep_cols]\n",
    "\n",
    "        for code in param_codes_2024:\n",
    "            if code in f.columns:\n",
    "                f[code] = pd.to_numeric(f[code], errors='coerce')\n",
    "        f['station_code'] = code_clean\n",
    "        frames_2024.append(f)\n",
    "\n",
    "df_2024_all_stations_processed = pd.concat(frames_2024, ignore_index=True) if frames_2024 else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ec60a6a18351fc1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:33:31.336470Z",
     "start_time": "2025-08-21T18:33:26.609348Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset five\n",
    "df_2025_all_stations = pd.read_excel(\n",
    "    Path(\"../data/raw/BD 2025.xlsx\"),\n",
    "    sheet_name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cf726e52235f349",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:41:47.775316Z",
     "start_time": "2025-08-21T18:41:47.604300Z"
    }
   },
   "outputs": [],
   "source": [
    "# Process dataset 5\n",
    "frames_2025 = []\n",
    "for sheet_name, frame in df_2025_all_stations.items():\n",
    "    code_clean = str(sheet_name).strip().upper()\n",
    "    if code_clean in labels['stations'].keys():\n",
    "        f = frame.copy()\n",
    "\n",
    "        if len(f) > 0:\n",
    "\t        f = f.drop(f.index[0]).reset_index(drop=True)\n",
    "\n",
    "        if 'date' in f.columns:\n",
    "            f['date'] = pd.to_datetime(f['date'], errors='coerce')\n",
    "\n",
    "            f['station_code'] = code_clean\n",
    "            frames_2025.append(f)\n",
    "\n",
    "df_2025_all_stations_processed = pd.concat(frames_2025, ignore_index=True) if frames_2025 else pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9740824c8348a76c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:43:07.121141Z",
     "start_time": "2025-08-21T18:43:06.687701Z"
    }
   },
   "outputs": [],
   "source": [
    "# Concat all dataframes\n",
    "main_dataframe = pd.concat(\n",
    "    [\n",
    "        df_2020_2021_all_stations_processed,\n",
    "        df_2022_2023_all_stations_processed,\n",
    "        df_2023_2024_all_stations_processed_no_2024,\n",
    "        df_2024_all_stations_processed,\n",
    "        df_2025_all_stations_processed\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5f55f2ba7bb95b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-21T18:43:18.806363Z",
     "start_time": "2025-08-21T18:43:09.000876Z"
    }
   },
   "outputs": [],
   "source": [
    "Path(\"../data/processed\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_2020_2021_all_stations_processed.to_csv(\n",
    "    Path(\"../data/processed/df_2020_2021_all_stations_processed.csv\"),\n",
    "    index=False,\n",
    "\n",
    ")\n",
    "df_2022_2023_all_stations_processed.to_csv(\n",
    "    Path(\"../data/processed/df_2022_2023_all_stations_processed.csv\"),\n",
    "    index=False\n",
    ")\n",
    "df_2023_2024_all_stations_processed_no_2024.to_csv(\n",
    "\tPath(\"../data/processed/df_2023_2024_all_stations_processed_no_2024.csv\"),\n",
    "\tindex=False\n",
    ")\n",
    "df_2024_all_stations_processed.to_csv(\n",
    "    Path(\"../data/processed/df_2024_all_stations_processed.csv\"),\n",
    "    index=False\n",
    ")\n",
    "df_2025_all_stations_processed.to_csv(\n",
    "\tPath(\"../data/processed/df_2025_all_stations_processed.csv\"),\n",
    "\tindex=False\n",
    ")\n",
    "\n",
    "main_dataframe.to_csv(\n",
    "\tPath(\"../data/processed/main_dataframe.csv\"),\n",
    "\tindex=False\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
