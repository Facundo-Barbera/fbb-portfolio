\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{setspace}
\usepackage{enumitem}

\setstretch{1.2}

\begin{document}

\begin{center}
\textbf{Reflexión Individual: Análisis de Datos Ambientales y Métodos Estadísticos} \\
Instituto Tecnológico de Estudios Superiores de Monterrey \\
MA2003B.102 Application of Multivariate Methods in Data Science \\
\end{center}

\section*{Introducción}
El desarrollo de este proyecto representó una experiencia integral para aplicar conocimientos matemáticos, estadísticos y tecnológicos a un problema de alta relevancia social: la contaminación atmosférica en la Zona Metropolitana de Monterrey (ZMM). El trabajo consistió en tomar datos reales, complejos y con un nivel significativo de inconsistencias para transformarlos en información estructurada y analizable.
Esto me permitió comprender cómo la estadística aplicada y la programación en entornos científicos pueden convertirse en herramientas clave para apoyar la toma de decisiones públicas y privadas.

El reto también involucró aprender a comunicar resultados científicos de manera clara, justificando la elección de métodos y destacando tanto sus ventajas como sus limitaciones.
Esta experiencia reforzó la importancia de que el análisis de datos no solo se centre en cálculos, sino también en el contexto social, económico y ambiental que les da sentido.


\section*{Base de datos}
La información utilizada provino de la Red de Monitoreo Ambiental de Nuevo León (SIMA), la cual integra series temporales con registros horarios de contaminantes criterio (PM10, PM2.5, NO$_2$, NO, CO, O$_3$, SO$_2$, NOx) y variables meteorológicas (temperatura, humedad, radiación solar, precipitación, presión, viento). El dataset original abarcaba más de 779,000 observaciones, con datos heterogéneos en estructura y con problemas de registros faltantes.

La fase de preparación de datos fue esencial. El procesamiento incluyó:
\begin{enumerate}[label=\alph*)]
  \item Unificación de cinco estructuras distintas de Excel,
  \item Homologación de nombres de variables y códigos de estaciones,
  \item Eliminación de duplicados,
  \item Filtrado de outliers por umbrales de plausibilidad.
\end{enumerate}

A partir de estas tareas se construyó un dataframe maestro con 17 columnas estandarizadas, asegurando trazabilidad y replicabilidad. Este trabajo me enseñó que un buen análisis depende, en gran medida, de la calidad del preprocesamiento.

\section*{Métodos estadísticos y tecnológicos}
Se emplearon dos bloques principales: imputación jerárquica y análisis exploratorio de datos.
\subsection*{Imputación jerárquica de datos faltantes}
Se diseñó un enfoque de tres niveles:
\begin{enumerate}[label=\arabic*.]
  \item Interpolación temporal para brechas cortas,
  \item Borrowing espacial con estaciones vecinas,
  \item Mantener huecos extensos como NA para evitar sesgos.
\end{enumerate}

Este esquema se comparó con tres métodos específicos:
\begin{itemize}
  \item MTB (Mean Top--Bottom): promedio de valores adyacentes,
  \item Nearest Neighbour: relleno con observaciones más cercanas en el tiempo,
  \item Iterative (MICE-like): imputación multivariada.
\end{itemize}

La validación mediante MAE y RMSE mostró que el método MTB ofrecía mejor balance entre precisión y capacidad de capturar picos de contaminación.

\subsection*{Análisis exploratorio}
Se realizaron estadísticas descriptivas, boxplots y series temporales. Los promedios móviles de 8 horas en contaminantes como O$_3$ y CO fueron útiles para cumplir con criterios normativos y detectar episodios críticos. También se realizaron comparaciones interanuales para identificar variaciones significativas en periodos clave: pandemia (2020--2021), reactivación económica (2024) y situación actual (2025).

Este proceso requirió integrar conocimientos de programación en R, manejo de librerías estadísticas y visualización de datos. Además, se evaluó la sensibilidad de los resultados a outliers y se verificó consistencia entre estaciones.

\section*{Resultados}
Durante la pandemia (2020), las reducciones más marcadas se observaron en contaminantes asociados a tránsito vehicular (NO$_2$, NOx, CO), confirmando el efecto inmediato de la reducción en movilidad. El PM2.5 también disminuyó, aunque con picos aislados debido a factores meteorológicos.

En contraste, durante la reactivación económica de 2024 se alcanzaron niveles críticos de contaminación: el PM2.5 superó con mayor frecuencia umbrales de 50 µg/m$^3$, mientras que NOx y ozono presentaron episodios extremos. Finalmente, en 2025 se observó una mejora parcial, pero sin regresar a los niveles mínimos registrados durante el confinamiento.

La interpretación de los resultados permitió concluir que las fuentes móviles continúan siendo el factor dominante de la contaminación en la ZMM. Asimismo, el ozono se consolidó como contaminante crítico a mediano plazo, ya que aunque sus medianas permanecieron estables, los picos máximos crecieron en intensidad y frecuencia.

\section*{Conclusión}
Este proyecto representó una oportunidad para unir teoría y práctica. Aprendí que los métodos estadísticos, más allá de generar números, permiten construir evidencia sólida para interpretar fenómenos sociales y ambientales. La imputación jerárquica, en particular, me mostró cómo la creatividad y el rigor científico pueden combinarse para resolver problemas reales de bases incompletas.

En lo personal, reforcé competencias en programación (RStudio, librerías estadísticas), en visualización de datos (boxplots, series temporales, comparaciones interanuales) y en el pensamiento crítico al vincular resultados con el contexto socioeconómico. A nivel reflexivo, entendí que la estadística aplicada es una herramienta fundamental para comunicar hallazgos de manera clara y argumentada.

Considero que esta experiencia no solo me permitió fortalecer mis habilidades técnicas, sino también generar una visión integral: los datos deben traducirse en información útil, y esta en conocimiento accionable para la toma de decisiones. En un futuro académico y profesional, este aprendizaje será valioso para enfrentar retos complejos donde la intersección entre datos, sociedad y tecnología será cada vez más importante.

\end{document}
